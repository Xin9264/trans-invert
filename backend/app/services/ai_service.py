"""é€šç”¨AIæœåŠ¡ - æ”¯æŒå¤šç§AIæä¾›å•†"""
import asyncio
import json
import os
import re
from enum import Enum
from typing import Dict, Any, Optional
from openai import OpenAI, AsyncOpenAI
from app.core.settings import settings
from app.services.template_service import template_service

class AIProvider(str, Enum):
    """AIæä¾›å•†æšä¸¾"""
    DEEPSEEK = "deepseek"
    VOLCANO = "volcano"
    OPENAI = "openai"

class AIService:
    """é€šç”¨AIæœåŠ¡å®¢æˆ·ç«¯"""
    
    def __init__(self):
        self.config_file = "ai_providers.json"
        self.provider = self._get_provider()
        self.api_key = self._get_api_key()
        self.base_url = self._get_base_url()
        self.model = self._get_model()
        
        # æ£€æŸ¥é…ç½®
        if not self.api_key:
            self._create_default_env()
            raise ValueError(f"AIé…ç½®æœªæ‰¾åˆ°ï¼Œè¯·é…ç½®ç›¸åº”çš„APIå¯†é’¥")
        
        # åˆå§‹åŒ–å®¢æˆ·ç«¯
        self.client = self._init_client()
        self.async_client = self._init_async_client()
    
    def _get_provider(self) -> AIProvider:
        """è·å–AIæä¾›å•†"""
        provider = os.getenv("AI_PROVIDER", "").lower()
        if provider == "volcano":
            return AIProvider.VOLCANO
        elif provider == "openai":
            return AIProvider.OPENAI
        else:
            return AIProvider.DEEPSEEK  # é»˜è®¤ä½¿ç”¨DeepSeek
    
    def _get_api_key(self) -> str:
        """è·å–APIå¯†é’¥ - æ‰«æå¤šç§å¯èƒ½çš„ç¯å¢ƒå˜é‡"""
        possible_keys = []
        
        if self.provider == AIProvider.VOLCANO:
            possible_keys = ["ARK_API_KEY", "VOLCANO_API_KEY", "DOUBAO_API_KEY"]
        elif self.provider == AIProvider.OPENAI:
            possible_keys = ["OPENAI_API_KEY", "OPENAI_KEY", "GPT_API_KEY"]
        else:  # DEEPSEEK
            possible_keys = ["DEEPSEEK_API_KEY", "DEEPSEEK_KEY"]
        
        # æ‰«ææ‰€æœ‰å¯èƒ½çš„ç¯å¢ƒå˜é‡
        for key_name in possible_keys:
            api_key = os.getenv(key_name, "").strip()
            if api_key and api_key != "your_deepseek_api_key_here" and api_key != "your_openai_api_key_here" and api_key != "your_ark_api_key_here":
                print(f"âœ… æ‰¾åˆ°æœ‰æ•ˆçš„APIå¯†é’¥: {key_name}")
                return api_key
        
        print(f"âš ï¸ æœªæ‰¾åˆ°æœ‰æ•ˆçš„APIå¯†é’¥ï¼Œæ‰«æçš„å˜é‡: {possible_keys}")
        return ""
    
    def _get_base_url(self) -> str:
        """è·å–APIåŸºç¡€URL"""
        if self.provider == AIProvider.VOLCANO:
            return os.getenv("ARK_BASE_URL", "https://ark.cn-beijing.volces.com/api/v3")
        elif self.provider == AIProvider.OPENAI:
            return os.getenv("OPENAI_BASE_URL", "https://api.openai.com/v1")
        else:
            return os.getenv("DEEPSEEK_BASE_URL", "https://api.deepseek.com")
    
    def _get_model(self) -> str:
        """è·å–æ¨¡å‹åç§°"""
        if self.provider == AIProvider.VOLCANO:
            return os.getenv("ARK_MODEL", "doubao-1-5-pro-32k-250115")
        elif self.provider == AIProvider.OPENAI:
            return os.getenv("OPENAI_MODEL", "gpt-4.1")
        else:
            return os.getenv("DEEPSEEK_MODEL", "deepseek-chat")
    
    def _init_client(self) -> OpenAI:
        """åˆå§‹åŒ–åŒæ­¥å®¢æˆ·ç«¯"""
        timeout = 1800 if self.provider == AIProvider.VOLCANO else 30
        return OpenAI(
            api_key=self.api_key,
            base_url=self.base_url,
            timeout=timeout
        )
    
    def _init_async_client(self) -> AsyncOpenAI:
        """åˆå§‹åŒ–å¼‚æ­¥å®¢æˆ·ç«¯"""
        timeout = 1800 if self.provider == AIProvider.VOLCANO else 30
        return AsyncOpenAI(
            api_key=self.api_key,
            base_url=self.base_url,
            timeout=timeout
        )
    
    def _create_default_env(self):
        """åˆ›å»ºé»˜è®¤çš„.envæ–‡ä»¶"""
        env_path = ".env"
        if not os.path.exists(env_path):
            default_env_content = """# AIæœåŠ¡é…ç½®
# é€‰æ‹©AIæä¾›å•†: deepseek, volcano, openai
AI_PROVIDER=deepseek

# DeepSeek é…ç½®
DEEPSEEK_API_KEY=your_deepseek_api_key_here
DEEPSEEK_BASE_URL=https://api.deepseek.com
DEEPSEEK_MODEL=deepseek-chat

# ç«å±±å¼•æ“ é…ç½®
ARK_API_KEY=your_ark_api_key_here
ARK_BASE_URL=https://ark.cn-beijing.volces.com/api/v3
ARK_MODEL=doubao-seed-1-6-250615

# OpenAI é…ç½®
OPENAI_API_KEY=your_openai_api_key_here
OPENAI_BASE_URL=https://api.openai.com/v1
OPENAI_MODEL=gpt-4.1

# åº”ç”¨é…ç½®
APP_ENV=dev
APP_HOST=0.0.0.0
APP_PORT=8000
DEBUG=true
ALLOWED_ORIGINS=http://localhost:3000
"""
            with open(env_path, 'w', encoding='utf-8') as f:
                f.write(default_env_content)
            print(f"âœ… å·²åˆ›å»ºé»˜è®¤é…ç½®æ–‡ä»¶: {env_path}")
    
    def reconfigure(self, provider: str = None, api_key: str = None, base_url: str = None, model: str = None):
        """åŠ¨æ€é‡æ–°é…ç½®AIæœåŠ¡"""
        try:
            # æ›´æ–°æä¾›å•†
            if provider:
                # éªŒè¯æä¾›å•†æ˜¯å¦æœ‰æ•ˆ
                if provider not in [p.value for p in AIProvider]:
                    raise ValueError(f"ä¸æ”¯æŒçš„AIæä¾›å•†: {provider}")
                
                # ä¸´æ—¶æ›´æ–°ç¯å¢ƒå˜é‡
                os.environ["AI_PROVIDER"] = provider
                self.provider = AIProvider(provider)
            
            # æ›´æ–°APIå¯†é’¥
            if api_key:
                if self.provider == AIProvider.VOLCANO:
                    os.environ["ARK_API_KEY"] = api_key
                elif self.provider == AIProvider.OPENAI:
                    os.environ["OPENAI_API_KEY"] = api_key
                else:
                    os.environ["DEEPSEEK_API_KEY"] = api_key
                self.api_key = api_key
            else:
                self.api_key = self._get_api_key()
            
            # æ›´æ–°åŸºç¡€URL
            if base_url:
                if self.provider == AIProvider.VOLCANO:
                    os.environ["ARK_BASE_URL"] = base_url
                elif self.provider == AIProvider.OPENAI:
                    os.environ["OPENAI_BASE_URL"] = base_url
                else:
                    os.environ["DEEPSEEK_BASE_URL"] = base_url
                self.base_url = base_url
            else:
                self.base_url = self._get_base_url()
            
            # æ›´æ–°æ¨¡å‹
            if model:
                if self.provider == AIProvider.VOLCANO:
                    os.environ["ARK_MODEL"] = model
                elif self.provider == AIProvider.OPENAI:
                    os.environ["OPENAI_MODEL"] = model
                else:
                    os.environ["DEEPSEEK_MODEL"] = model
                self.model = model
            else:
                self.model = self._get_model()
            
            # æ£€æŸ¥APIå¯†é’¥
            if not self.api_key:
                raise ValueError(f"ç¼ºå°‘{self.provider.value}çš„APIå¯†é’¥")
            
            # é‡æ–°åˆå§‹åŒ–å®¢æˆ·ç«¯
            self.client = self._init_client()
            self.async_client = self._init_async_client()
            
            # ä¿å­˜é…ç½®åˆ°æ–‡ä»¶
            if api_key:  # åªæœ‰æä¾›äº†æ–°çš„APIå¯†é’¥æ‰ä¿å­˜
                self._save_config(self.provider.value, api_key, self.base_url, self.model)
            
            print(f"âœ… AIæœåŠ¡å·²é‡æ–°é…ç½®: {self.get_provider_info()}")
            return True
            
        except Exception as e:
            print(f"âŒ AIæœåŠ¡é‡æ–°é…ç½®å¤±è´¥: {e}")
            return False
    
    def _load_saved_configs(self) -> Dict[str, Dict[str, str]]:
        """åŠ è½½å·²ä¿å­˜çš„é…ç½®"""
        try:
            if os.path.exists(self.config_file):
                with open(self.config_file, 'r', encoding='utf-8') as f:
                    return json.load(f)
        except Exception as e:
            print(f"âš ï¸ åŠ è½½é…ç½®æ–‡ä»¶å¤±è´¥: {e}")
        return {}
    
    def _save_config(self, provider: str, api_key: str, base_url: str, model: str):
        """ä¿å­˜æä¾›å•†é…ç½®"""
        try:
            configs = self._load_saved_configs()
            configs[provider] = {
                "api_key": api_key,
                "base_url": base_url,
                "model": model,
                "configured_at": json.dumps({"timestamp": "now"})  # ç®€åŒ–çš„æ—¶é—´æˆ³
            }
            
            with open(self.config_file, 'w', encoding='utf-8') as f:
                json.dump(configs, f, ensure_ascii=False, indent=2)
            
            print(f"âœ… å·²ä¿å­˜ {provider} é…ç½®")
        except Exception as e:
            print(f"âŒ ä¿å­˜é…ç½®å¤±è´¥: {e}")
    
    def get_all_configured_providers(self) -> Dict[str, Dict[str, Any]]:
        """è·å–æ‰€æœ‰å·²é…ç½®çš„æä¾›å•†"""
        configs = self._load_saved_configs()
        result = {}
        
        for provider, config in configs.items():
            if config.get("api_key"):
                result[provider] = {
                    "provider": provider,
                    "model": config.get("model", ""),
                    "base_url": config.get("base_url", ""),
                    "api_key_configured": True,
                    "api_key_preview": "***å·²é…ç½®***"  # å®Œå…¨éšè—APIå¯†é’¥
                }
        
        return result
    
    def switch_to_provider(self, provider: str) -> bool:
        """åˆ‡æ¢åˆ°å·²é…ç½®çš„æä¾›å•†"""
        try:
            configs = self._load_saved_configs()
            if provider not in configs:
                raise ValueError(f"æä¾›å•† {provider} æœªé…ç½®")
            
            config = configs[provider]
            return self.reconfigure(
                provider=provider,
                api_key=config["api_key"],
                base_url=config["base_url"],
                model=config["model"]
            )
        except Exception as e:
            print(f"âŒ åˆ‡æ¢æä¾›å•†å¤±è´¥: {e}")
            return False
    
    def get_provider_info(self) -> Dict[str, Any]:
        """è·å–å½“å‰æä¾›å•†ä¿¡æ¯"""
        return {
            "provider": self.provider.value,
            "model": self.model,
            "base_url": self.base_url,
            "api_key_configured": bool(self.api_key),
            "api_key_preview": "***å·²é…ç½®***" if self.api_key else "æœªé…ç½®"  # å®Œå…¨éšè—APIå¯†é’¥
        }
    
    @staticmethod
    def scan_environment_keys() -> Dict[str, Any]:
        """æ‰«æç¯å¢ƒå˜é‡ä¸­çš„APIå¯†é’¥é…ç½®"""
        scan_result = {
            "deepseek": {"found": False, "keys": [], "valid_key": None},
            "openai": {"found": False, "keys": [], "valid_key": None},
            "volcano": {"found": False, "keys": [], "valid_key": None}
        }
        
        # å®šä¹‰æ‰€æœ‰å¯èƒ½çš„ç¯å¢ƒå˜é‡å
        all_possible_keys = {
            "deepseek": ["DEEPSEEK_API_KEY", "DEEPSEEK_KEY"],
            "openai": ["OPENAI_API_KEY", "OPENAI_KEY", "GPT_API_KEY"],
            "volcano": ["ARK_API_KEY", "VOLCANO_API_KEY", "DOUBAO_API_KEY"]
        }
        
        # æ‰«ææ‰€æœ‰ç¯å¢ƒå˜é‡
        for provider, key_names in all_possible_keys.items():
            for key_name in key_names:
                api_key = os.getenv(key_name, "").strip()
                if api_key:
                    scan_result[provider]["keys"].append({
                        "name": key_name,
                        "preview": f"{api_key[:8]}..." if len(api_key) > 8 else "çŸ­å¯†é’¥",
                        "is_placeholder": api_key in ["your_deepseek_api_key_here", "your_openai_api_key_here", "your_ark_api_key_here"]
                    })
                    
                    # æ£€æŸ¥æ˜¯å¦æ˜¯æœ‰æ•ˆå¯†é’¥ï¼ˆéå ä½ç¬¦ï¼‰
                    if api_key not in ["your_deepseek_api_key_here", "your_openai_api_key_here", "your_ark_api_key_here"]:
                        scan_result[provider]["found"] = True
                        if not scan_result[provider]["valid_key"]:
                            scan_result[provider]["valid_key"] = key_name
        
        return {
            "scan_result": scan_result,
            "summary": {
                "total_providers_configured": sum(1 for p in scan_result.values() if p["found"]),
                "recommended_provider": next((k for k, v in scan_result.items() if v["found"]), "deepseek"),
                "needs_configuration": not any(p["found"] for p in scan_result.values())
            }
        }
    
    async def _call_api(self, prompt: str) -> str:
        """è°ƒç”¨AI API"""
        try:
            # æ ¹æ®æä¾›å•†è®¾ç½®ä¸åŒçš„å‚æ•°
            api_params = {
                "model": self.model,
                "messages": [
                    {
                        "role": "system",
                        "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„è‹±è¯­æ•™å­¦åŠ©æ‰‹ï¼Œä¸“é—¨å¸®åŠ©ä¸­å›½å­¦ç”Ÿå­¦ä¹ è‹±è¯­ã€‚è¯·ä¸¥æ ¼æŒ‰ç…§è¦æ±‚è¿”å›JSONæ ¼å¼çš„ç»“æœã€‚"
                    },
                    {
                        "role": "user",
                        "content": prompt
                    }
                ],
            }
            
            # OpenAI ä½¿ç”¨ max_completion_tokensï¼Œå…¶ä»–æä¾›å•†ä½¿ç”¨ max_tokens
            if self.provider == AIProvider.OPENAI:
                api_params["max_completion_tokens"] = 2000
            else:
                api_params["max_tokens"] = 2000
                
            response = await self.async_client.chat.completions.create(**api_params)
            
            # å¤„ç†ç«å±±å¼•æ“çš„ç‰¹æ®Šå“åº”æ ¼å¼
            if self.provider == AIProvider.VOLCANO and hasattr(response.choices[0].message, 'reasoning_content'):
                reasoning = response.choices[0].message.reasoning_content
                content = response.choices[0].message.content
                print(f"ğŸ’­ æ¨ç†è¿‡ç¨‹: {reasoning}")
                return content
            
            return response.choices[0].message.content
            
        except Exception as e:
            raise Exception(f"{self.provider.value} APIè¯·æ±‚å¤±è´¥: {str(e)}")
    
    def _extract_json_from_response(self, response: str) -> Dict[str, Any]:
        """ä»å“åº”ä¸­æå–JSONå†…å®¹"""
        try:
            # å°è¯•ç›´æ¥è§£æ
            return json.loads(response)
        except json.JSONDecodeError:
            # å°è¯•æå–JSONéƒ¨åˆ†
            json_match = re.search(r'\{[\s\S]*\}', response)
            if json_match:
                try:
                    return json.loads(json_match.group())
                except json.JSONDecodeError:
                    pass
            
            # å¦‚æœæ— æ³•è§£æï¼Œè¿”å›é”™è¯¯ä¿¡æ¯
            raise Exception(f"æ— æ³•è§£æAIå“åº”ä¸ºJSONæ ¼å¼: {response}")
    
    async def analyze_text(self, text_content: str) -> Dict[str, Any]:
        """åˆ†æè‹±æ–‡æ–‡æœ¬"""
        try:
            # ä½¿ç”¨æ¨¡æ¿æ¸²æŸ“æç¤ºè¯
            prompt = template_service.render_analyze_text_prompt(text_content)
            
            # è°ƒç”¨API
            response = await self._call_api(prompt)
            
            # è§£æJSONå“åº”
            result = self._extract_json_from_response(response)
            
            # éªŒè¯å¿…è¦å­—æ®µ
            required_fields = ["translation", "difficult_words", "difficulty", "key_points"]
            for field in required_fields:
                if field not in result:
                    raise Exception(f"AIå“åº”ç¼ºå°‘å¿…è¦å­—æ®µ: {field}")
            
            # ç¡®ä¿æ•°æ®ç±»å‹æ­£ç¡®
            result["difficulty"] = int(result["difficulty"])
            if not isinstance(result["difficult_words"], list):
                result["difficult_words"] = []
            if not isinstance(result["key_points"], list):
                result["key_points"] = []
            
            return result
            
        except Exception as e:
            # è¿”å›é»˜è®¤ç»“æœ
            return {
                "translation": f"æ–‡æœ¬åˆ†æå¤±è´¥: {str(e)}",
                "difficult_words": [{"word": "åˆ†æå¤±è´¥", "meaning": "è¯·ç¨åé‡è¯•"}],
                "difficulty": 3,
                "key_points": ["åˆ†æå¤±è´¥"]
            }
    
    async def evaluate_answer_stream(
        self, 
        original_text: str, 
        translation: str, 
        user_input: str
    ):
        """æµå¼è¯„ä¼°ç”¨æˆ·ç­”æ¡ˆï¼Œå¸¦é‡è¯•æœºåˆ¶"""
        max_retries = 2
        
        for attempt in range(max_retries + 1):
            try:
                # å‘é€é‡è¯•çŠ¶æ€é€šçŸ¥
                if attempt > 0:
                    yield {
                        "type": "progress",
                        "progress": 0,
                        "content": f"æ­£åœ¨é‡è¯• (å°è¯• {attempt + 1}/{max_retries + 1})..."
                    }
                    # çŸ­æš‚ç­‰å¾…
                    await asyncio.sleep(1)
                
                # è¿›è¡Œå®é™…çš„æµå¼è¯„ä¼°
                success = False
                last_error = None
                
                async for result in self._do_stream_evaluation(original_text, translation, user_input, attempt + 1, max_retries + 1):
                    yield result
                    
                    # æ£€æŸ¥æ˜¯å¦æˆåŠŸå®Œæˆ
                    if result.get("type") == "complete":
                        success = True
                        return  # æˆåŠŸå®Œæˆï¼Œé€€å‡ºæ‰€æœ‰é‡è¯•
                    elif result.get("type") == "error":
                        last_error = result.get("error", "æœªçŸ¥é”™è¯¯")
                        break  # è·³å‡ºå†…å±‚å¾ªç¯ï¼Œè¿›è¡Œé‡è¯•
                
                if success:
                    return
                    
            except Exception as e:
                last_error = str(e)
                print(f"âš ï¸ ç¬¬ {attempt + 1} æ¬¡å°è¯•å¤±è´¥: {e}")
                
                if attempt < max_retries:
                    yield {
                        "type": "progress",
                        "progress": 0,
                        "content": f"ç½‘ç»œå¼‚å¸¸ï¼Œæ­£åœ¨é‡è¯•... ({attempt + 2}/{max_retries + 1})"
                    }
                    await asyncio.sleep(2)  # ç­‰å¾…åé‡è¯•
                    continue
        
        # æ‰€æœ‰é‡è¯•éƒ½å¤±è´¥äº†ï¼Œè¿”å›é»˜è®¤ç»“æœ
        print(f"âŒ æ‰€æœ‰é‡è¯•éƒ½å¤±è´¥ï¼Œè¿”å›é»˜è®¤ç»“æœã€‚æœ€åé”™è¯¯: {last_error}")
        yield {
            "type": "complete",
            "result": {
                "score": 70,
                "corrections": [],
                "overall_feedback": f"è¯„ä¼°æœåŠ¡æš‚æ—¶ä¸å¯ç”¨ï¼Œè¯·ç¨åé‡è¯•ã€‚é”™è¯¯: {last_error or 'ç½‘ç»œè¿æ¥å¼‚å¸¸'}",
                "is_acceptable": True
            },
            "progress": 100
        }
    
    async def _do_stream_evaluation(
        self, 
        original_text: str, 
        translation: str, 
        user_input: str,
        current_attempt: int,
        max_attempts: int
    ):
        """æ‰§è¡Œå•æ¬¡æµå¼è¯„ä¼°"""
        try:
            # ä½¿ç”¨æ¨¡æ¿æ¸²æŸ“æç¤ºè¯
            prompt = template_service.render_evaluate_answer_prompt(
                original_text=original_text,
                translation=translation,
                user_input=user_input
            )
            
            yield {
                "type": "progress",
                "progress": 10,
                "content": f"å¼€å§‹AIè¯„ä¼°... (å°è¯• {current_attempt}/{max_attempts})"
            }
            
            # æµå¼è¯„ä¼°
            stream_params = {
                "model": self.model,
                "messages": [{"role": "user", "content": prompt}],
                "stream": True
            }
            
            # OpenAI ä½¿ç”¨ max_completion_tokensï¼Œå…¶ä»–æä¾›å•†ä½¿ç”¨ max_tokens
            if self.provider == AIProvider.OPENAI:
                stream_params["max_completion_tokens"] = 2000
            else:
                stream_params["max_tokens"] = 2000
                
            response = await self.async_client.chat.completions.create(**stream_params)
            
            collected_content = ""
            chunk_count = 0
            
            async for chunk in response:
                if chunk.choices[0].delta.content is not None:
                    content = chunk.choices[0].delta.content
                    collected_content += content
                    chunk_count += 1
                    
                    # è®¡ç®—è¿›åº¦
                    progress = self._calculate_json_progress(collected_content)
                    yield {
                        "type": "progress",
                        "content": content,
                        "progress": min(90, progress),
                        "full_content": collected_content
                    }
            
            # éªŒè¯å“åº”å†…å®¹
            if len(collected_content.strip()) < 10:
                raise Exception("AIå“åº”å†…å®¹ä¸ºç©ºæˆ–è¿‡çŸ­")
            
            if chunk_count == 0:
                raise Exception("æ²¡æœ‰æ”¶åˆ°æœ‰æ•ˆçš„æµå¼æ•°æ®")
            
            # å¤„ç†å®Œæ•´å“åº”
            try:
                result = self._extract_json_from_response(collected_content)
                
                # éªŒè¯å’Œæ¸…ç†æ•°æ®
                required_fields = ["score", "corrections", "overall_feedback", "is_acceptable"]
                for field in required_fields:
                    if field not in result:
                        raise Exception(f"AIå“åº”ç¼ºå°‘å¿…è¦å­—æ®µ: {field}")
                
                result["score"] = int(result["score"])
                result["score"] = max(0, min(100, result["score"]))
                
                if not isinstance(result["corrections"], list):
                    result["corrections"] = []
                
                result["is_acceptable"] = bool(result["is_acceptable"])
                
                yield {
                    "type": "complete",
                    "result": result,
                    "progress": 100
                }
                
            except Exception as e:
                # è§£æå¤±è´¥ï¼ŒæŠ›å‡ºå¼‚å¸¸è®©é‡è¯•æœºåˆ¶å¤„ç†
                raise Exception(f"è§£æAIå“åº”å¤±è´¥: {str(e)}")
                
        except Exception as e:
            yield {
                "type": "error",
                "error": str(e),
                "progress": 0
            }

    def _calculate_json_progress(self, content: str) -> int:
        """æ ¹æ®JSONå­—æ®µçš„å‡ºç°æƒ…å†µè®¡ç®—è¿›åº¦"""
        progress = 0
        
        # å®šä¹‰å…³é”®å­—æ®µåŠå…¶æƒé‡
        key_fields = {
            '"score"': 25,
            '"corrections"': 25, 
            '"overall_feedback"': 25,
            '"is_acceptable"': 25
        }
        
        for field, weight in key_fields.items():
            if field in content:
                progress += weight
        
        # å¦‚æœåŒ…å«å®Œæ•´çš„JSONç»“æ„ï¼Œç»™äºˆé¢å¤–åˆ†æ•°
        if content.count('{') > 0 and content.count('}') > 0:
            if content.count('{') == content.count('}'):
                progress = min(100, progress + 10)
        
        return min(100, progress)

    async def evaluate_answer(
        self, 
        original_text: str, 
        translation: str, 
        user_input: str
    ) -> Dict[str, Any]:
        """è¯„ä¼°ç”¨æˆ·ç­”æ¡ˆ"""
        try:
            # ä½¿ç”¨æ¨¡æ¿æ¸²æŸ“æç¤ºè¯
            prompt = template_service.render_evaluate_answer_prompt(
                original_text=original_text,
                translation=translation,
                user_input=user_input
            )
            
            # è°ƒç”¨API
            response = await self._call_api(prompt)
            
            # è§£æJSONå“åº”
            result = self._extract_json_from_response(response)
            
            # éªŒè¯å¿…è¦å­—æ®µ
            required_fields = ["score", "corrections", "overall_feedback", "is_acceptable"]
            for field in required_fields:
                if field not in result:
                    raise Exception(f"AIå“åº”ç¼ºå°‘å¿…è¦å­—æ®µ: {field}")
            
            # ç¡®ä¿æ•°æ®ç±»å‹æ­£ç¡®
            result["score"] = int(result["score"])
            result["score"] = max(0, min(100, result["score"]))  # é™åˆ¶åœ¨0-100èŒƒå›´å†…
            
            if not isinstance(result["corrections"], list):
                result["corrections"] = []
            
            result["is_acceptable"] = bool(result["is_acceptable"])
            
            return result
            
        except Exception as e:
            # è¿”å›é»˜è®¤è¯„ä¼°ç»“æœ
            return {
                "score": 70,
                "corrections": [],
                "overall_feedback": f"è¯„ä¼°å¤±è´¥: {str(e)}ï¼Œè¯·ç¨åé‡è¯•ã€‚",
                "is_acceptable": True
            }

    async def generate_essay(
        self, 
        topic: str, 
        exam_type: str, 
        requirements: str = None
    ) -> Dict[str, Any]:
        """ç”Ÿæˆä½œæ–‡èŒƒæ–‡"""
        try:
            # ä½¿ç”¨æ¨¡æ¿æ¸²æŸ“æç¤ºè¯
            prompt = template_service.render_generate_essay_prompt(
                topic=topic,
                exam_type=exam_type,
                requirements=requirements
            )
            
            # è°ƒç”¨API
            response = await self._call_api(prompt)
            
            # è§£æJSONå“åº”
            result = self._extract_json_from_response(response)
            
            # éªŒè¯å¿…è¦å­—æ®µ
            required_fields = ["english_essay", "chinese_translation"]
            for field in required_fields:
                if field not in result:
                    raise Exception(f"AIå“åº”ç¼ºå°‘å¿…è¦å­—æ®µ: {field}")
            
            return result
            
        except Exception as e:
            # è¿”å›é»˜è®¤ç»“æœ
            return {
                "english_essay": f"ä½œæ–‡ç”Ÿæˆå¤±è´¥: {str(e)}",
                "chinese_translation": f"ä½œæ–‡ç”Ÿæˆå¤±è´¥: {str(e)}"
            }

    async def generate_essay_stream(
        self, 
        topic: str, 
        exam_type: str, 
        requirements: str = None
    ):
        """æµå¼ç”Ÿæˆä½œæ–‡èŒƒæ–‡"""
        try:
            # ä½¿ç”¨æ¨¡æ¿æ¸²æŸ“æç¤ºè¯
            prompt = template_service.render_generate_essay_prompt(
                topic=topic,
                exam_type=exam_type,
                requirements=requirements
            )
            
            yield {
                "type": "progress",
                "progress": 10,
                "content": "å¼€å§‹ç”Ÿæˆä½œæ–‡èŒƒæ–‡..."
            }
            
            # æµå¼ç”Ÿæˆ
            stream_params = {
                "model": self.model,
                "messages": [{"role": "user", "content": prompt}],
                "stream": True
            }
            
            # OpenAI ä½¿ç”¨ max_completion_tokensï¼Œå…¶ä»–æä¾›å•†ä½¿ç”¨ max_tokens
            if self.provider == AIProvider.OPENAI:
                stream_params["max_completion_tokens"] = 3000
            else:
                stream_params["max_tokens"] = 3000
                
            response = await self.async_client.chat.completions.create(**stream_params)
            
            collected_content = ""
            chunk_count = 0
            
            async for chunk in response:
                if chunk.choices[0].delta.content is not None:
                    content = chunk.choices[0].delta.content
                    collected_content += content
                    chunk_count += 1
                    
                    # è®¡ç®—è¿›åº¦
                    progress = self._calculate_essay_progress(collected_content)
                    yield {
                        "type": "progress",
                        "content": content,
                        "progress": min(90, progress),
                        "full_content": collected_content
                    }
            
            # éªŒè¯å“åº”å†…å®¹
            if len(collected_content.strip()) < 10:
                raise Exception("AIå“åº”å†…å®¹ä¸ºç©ºæˆ–è¿‡çŸ­")
            
            # å¤„ç†å®Œæ•´å“åº”
            try:
                result = self._extract_json_from_response(collected_content)
                
                # éªŒè¯å¿…è¦å­—æ®µ
                required_fields = ["english_essay", "chinese_translation"]
                for field in required_fields:
                    if field not in result:
                        raise Exception(f"AIå“åº”ç¼ºå°‘å¿…è¦å­—æ®µ: {field}")
                
                yield {
                    "type": "complete",
                    "result": result,
                    "progress": 100
                }
                
            except Exception as e:
                raise Exception(f"è§£æAIå“åº”å¤±è´¥: {str(e)}")
                
        except Exception as e:
            yield {
                "type": "error",
                "error": str(e),
                "progress": 0
            }

    def _calculate_essay_progress(self, content: str) -> int:
        """æ ¹æ®ä½œæ–‡ç”Ÿæˆçš„è¿›åº¦è®¡ç®—ç™¾åˆ†æ¯”"""
        progress = 0
        
        # å®šä¹‰å…³é”®å­—æ®µåŠå…¶æƒé‡
        key_fields = {
            '"english_essay"': 50,
            '"chinese_translation"': 50
        }
        
        for field, weight in key_fields.items():
            if field in content:
                progress += weight
        
        # æ ¹æ®å†…å®¹é•¿åº¦å¢åŠ è¿›åº¦
        if len(content) > 100:
            progress += 10
        if len(content) > 500:
            progress += 10
        if len(content) > 1000:
            progress += 10
        
        return min(100, progress)

    async def evaluate_essay_stream(
        self, 
        topic: str,
        exam_type: str,
        sample_essay: str,
        user_essay: str
    ):
        """æµå¼è¯„ä¼°ç”¨æˆ·ä½œæ–‡"""
        try:
            # ä½¿ç”¨æ¨¡æ¿æ¸²æŸ“æç¤ºè¯
            prompt = template_service.render_evaluate_essay_prompt(
                topic=topic,
                exam_type=exam_type,
                sample_essay=sample_essay,
                user_essay=user_essay
            )
            
            yield {
                "type": "progress",
                "progress": 10,
                "content": "å¼€å§‹AIä½œæ–‡è¯„ä¼°..."
            }
            
            # æµå¼è¯„ä¼°
            stream_params = {
                "model": self.model,
                "messages": [{"role": "user", "content": prompt}],
                "stream": True
            }
            
            # OpenAI ä½¿ç”¨ max_completion_tokensï¼Œå…¶ä»–æä¾›å•†ä½¿ç”¨ max_tokens
            if self.provider == AIProvider.OPENAI:
                stream_params["max_completion_tokens"] = 2500
            else:
                stream_params["max_tokens"] = 2500
                
            response = await self.async_client.chat.completions.create(**stream_params)
            
            collected_content = ""
            chunk_count = 0
            
            async for chunk in response:
                if chunk.choices[0].delta.content is not None:
                    content = chunk.choices[0].delta.content
                    collected_content += content
                    chunk_count += 1
                    
                    # è®¡ç®—è¿›åº¦
                    progress = self._calculate_essay_evaluation_progress(collected_content)
                    yield {
                        "type": "progress",
                        "content": content,
                        "progress": min(90, progress),
                        "full_content": collected_content
                    }
            
            # éªŒè¯å“åº”å†…å®¹
            if len(collected_content.strip()) < 10:
                raise Exception("AIå“åº”å†…å®¹ä¸ºç©ºæˆ–è¿‡çŸ­")
            
            # å¤„ç†å®Œæ•´å“åº”
            try:
                result = self._extract_json_from_response(collected_content)
                
                # éªŒè¯å¿…è¦å­—æ®µ
                required_fields = ["overall_score", "detailed_scores", "strengths", "improvements", "specific_corrections", "overall_feedback"]
                for field in required_fields:
                    if field not in result:
                        raise Exception(f"AIå“åº”ç¼ºå°‘å¿…è¦å­—æ®µ: {field}")
                
                # æ ¹æ®è€ƒè¯•ç±»å‹éªŒè¯å’Œè°ƒæ•´åˆ†æ•°
                result = self._validate_essay_scores(result, exam_type)
                
                if not isinstance(result["strengths"], list):
                    result["strengths"] = []
                if not isinstance(result["improvements"], list):
                    result["improvements"] = []
                if not isinstance(result["specific_corrections"], list):
                    result["specific_corrections"] = []
                
                yield {
                    "type": "complete",
                    "result": result,
                    "progress": 100
                }
                
            except Exception as e:
                raise Exception(f"è§£æAIå“åº”å¤±è´¥: {str(e)}")
                
        except Exception as e:
            yield {
                "type": "error",
                "error": str(e),
                "progress": 0
            }

    def _calculate_essay_evaluation_progress(self, content: str) -> int:
        """æ ¹æ®ä½œæ–‡è¯„ä¼°çš„è¿›åº¦è®¡ç®—ç™¾åˆ†æ¯”"""
        progress = 0
        
        # å®šä¹‰å…³é”®å­—æ®µåŠå…¶æƒé‡
        key_fields = {
            '"overall_score"': 20,
            '"detailed_scores"': 20,
            '"strengths"': 15,
            '"improvements"': 15,
            '"specific_corrections"': 15,
            '"overall_feedback"': 15
        }
        
        for field, weight in key_fields.items():
            if field in content:
                progress += weight
        
        return min(100, progress)

    def _validate_essay_scores(self, result: Dict[str, Any], exam_type: str) -> Dict[str, Any]:
        """æ ¹æ®è€ƒè¯•ç±»å‹éªŒè¯å’Œè°ƒæ•´åˆ†æ•°"""
        # è€ƒè¯•ç±»å‹å¯¹åº”çš„åˆ†æ•°èŒƒå›´
        score_ranges = {
            'ielts': {'min': 0, 'max': 9, 'step': 0.5},  # é›…æ€ï¼š0-9åˆ†ï¼Œ0.5åˆ†åˆ¶
            'toefl': {'min': 0, 'max': 30, 'step': 1},   # æ‰˜ç¦ï¼š0-30åˆ†ï¼Œæ•´æ•°
            'cet4': {'min': 0, 'max': 100, 'step': 1},   # å››çº§ï¼š0-100åˆ†ï¼Œæ•´æ•°
            'cet6': {'min': 0, 'max': 100, 'step': 1},   # å…­çº§ï¼š0-100åˆ†ï¼Œæ•´æ•°
            'gre': {'min': 0, 'max': 6, 'step': 0.5}     # GREï¼š0-6åˆ†ï¼Œ0.5åˆ†åˆ¶
        }
        
        # è·å–å½“å‰è€ƒè¯•ç±»å‹çš„åˆ†æ•°èŒƒå›´ï¼Œé»˜è®¤ä½¿ç”¨100åˆ†åˆ¶
        score_config = score_ranges.get(exam_type, {'min': 0, 'max': 100, 'step': 1})
        min_score = score_config['min']
        max_score = score_config['max']
        step = score_config['step']
        
        # éªŒè¯æ€»åˆ†
        overall_score = float(result.get("overall_score", 0))
        overall_score = max(min_score, min(max_score, overall_score))
        
        # æ ¹æ®stepè°ƒæ•´åˆ†æ•°ï¼ˆå››èˆäº”å…¥åˆ°æœ€è¿‘çš„æœ‰æ•ˆåˆ†æ•°ï¼‰
        if step == 0.5:
            overall_score = round(overall_score * 2) / 2
        else:
            overall_score = round(overall_score)
        
        result["overall_score"] = overall_score
        
        # éªŒè¯åˆ†é¡¹å¾—åˆ†
        if "detailed_scores" in result and isinstance(result["detailed_scores"], dict):
            for key, score in result["detailed_scores"].items():
                score = float(score)
                score = max(min_score, min(max_score, score))
                
                # æ ¹æ®stepè°ƒæ•´åˆ†æ•°
                if step == 0.5:
                    score = round(score * 2) / 2
                else:
                    score = round(score)
                
                result["detailed_scores"][key] = score
        
        return result

# åˆ›å»ºå…¨å±€AIæœåŠ¡å®ä¾‹
try:
    ai_service = AIService()
    print(f"âœ… AIæœåŠ¡åˆå§‹åŒ–æˆåŠŸ: {ai_service.get_provider_info()}")
except Exception as e:
    print(f"âŒ AIæœåŠ¡åˆå§‹åŒ–å¤±è´¥: {e}")
    ai_service = None